{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfaaTSwurVHI",
        "outputId": "cd649c22-f535-48f6-acf0-e4b8f4c82ae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pix"
      ],
      "metadata": {
        "id": "V4GPApZMk34F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, use_batchnorm=True, use_leaky=True):\n",
        "        super().__init__()\n",
        "        layers = [nn.Conv2d(in_channels, out_channels, 4, 2, 1)]\n",
        "        if use_batchnorm:\n",
        "            layers.append(nn.BatchNorm2d(out_channels))\n",
        "        layers.append(nn.LeakyReLU(0.2) if use_leaky else nn.ReLU())\n",
        "        self.block = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "class UpConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, dropout=False, final=False):\n",
        "        super().__init__()\n",
        "        layers = [nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1)]\n",
        "        if not final:\n",
        "            layers.append(nn.BatchNorm2d(out_channels))\n",
        "            layers.append(nn.ReLU())\n",
        "            if dropout:\n",
        "                layers.append(nn.Dropout(0.5))\n",
        "        else:\n",
        "            layers.append(nn.Tanh())  # Output range [-1, 1]\n",
        "        self.block = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "class UNetGeneratorOptimized(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=3, features=64):\n",
        "        super().__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.enc1 = ConvBlock(in_channels, features, use_batchnorm=False)     # 64\n",
        "        self.enc2 = ConvBlock(features, features * 2)                          # 128\n",
        "        self.enc3 = ConvBlock(features * 2, features * 4)                      # 256\n",
        "        self.enc4 = ConvBlock(features * 4, features * 8)                      # 512\n",
        "        self.enc5 = ConvBlock(features * 8, features * 8)                      # 512\n",
        "        self.enc6 = ConvBlock(features * 8, features * 8)                      # 512\n",
        "        self.enc7 = ConvBlock(features * 8, features * 8)                      # 512\n",
        "        self.enc8 = ConvBlock(features * 8, features * 8, use_batchnorm=False) # bottleneck\n",
        "\n",
        "        # Decoder\n",
        "        self.dec1 = UpConvBlock(features * 8, features * 8, dropout=True)     # 512\n",
        "        self.dec2 = UpConvBlock(features * 8 * 2, features * 8, dropout=True)\n",
        "        self.dec3 = UpConvBlock(features * 8 * 2, features * 8, dropout=True)\n",
        "        self.dec4 = UpConvBlock(features * 8 * 2, features * 8)\n",
        "        self.dec5 = UpConvBlock(features * 8 * 2, features * 4)\n",
        "        self.dec6 = UpConvBlock(features * 4 * 2, features * 2)\n",
        "        self.dec7 = UpConvBlock(features * 2 * 2, features)\n",
        "        self.dec8 = UpConvBlock(features * 2, out_channels, final=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder path\n",
        "        e1 = self.enc1(x)\n",
        "        e2 = self.enc2(e1)\n",
        "        e3 = self.enc3(e2)\n",
        "        e4 = self.enc4(e3)\n",
        "        e5 = self.enc5(e4)\n",
        "        e6 = self.enc6(e5)\n",
        "        e7 = self.enc7(e6)\n",
        "        e8 = self.enc8(e7)\n",
        "\n",
        "        # Decoder path + skip connections\n",
        "        d1 = self.dec1(e8)\n",
        "        d2 = self.dec2(torch.cat([d1, e7], dim=1))\n",
        "        d3 = self.dec3(torch.cat([d2, e6], dim=1))\n",
        "        d4 = self.dec4(torch.cat([d3, e5], dim=1))\n",
        "        d5 = self.dec5(torch.cat([d4, e4], dim=1))\n",
        "        d6 = self.dec6(torch.cat([d5, e3], dim=1))\n",
        "        d7 = self.dec7(torch.cat([d6, e2], dim=1))\n",
        "        d8 = self.dec8(torch.cat([d7, e1], dim=1))\n",
        "\n",
        "        return d8\n"
      ],
      "metadata": {
        "id": "sT0aO8NbvxoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PairedImageDataset with DataAugmentation\n"
      ],
      "metadata": {
        "id": "FA8EP_M6wWKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "class PairedImageDataset(Dataset):\n",
        "    def __init__(self, input_dir, output_dir, augment=False):\n",
        "        self.input_paths = sorted([os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith(('jpg','png'))])\n",
        "        self.output_paths = sorted([os.path.join(output_dir, f) for f in os.listdir(output_dir) if f.endswith(('jpg','png'))])\n",
        "\n",
        "        base_transforms = [\n",
        "            transforms.Resize((1024, 1024)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)  # [0,1] → [-1,1]\n",
        "        ]\n",
        "\n",
        "        if augment:\n",
        "            self.transform = transforms.Compose([\n",
        "                transforms.Resize((1024, 1024)),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.RandomRotation(degrees=10),\n",
        "                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
        "            ])\n",
        "        else:\n",
        "            self.transform = transforms.Compose(base_transforms)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = Image.open(self.input_paths[idx]).convert(\"RGB\")\n",
        "        y = Image.open(self.output_paths[idx]).convert(\"RGB\")\n",
        "        return self.transform(x), self.transform(y)\n",
        "\n",
        "class PatchDiscriminator(nn.Module):\n",
        "    def __init__(self, in_channels=6, features=64):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, features, 4, 2, 1), nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(features, features*2, 4, 2, 1), nn.BatchNorm2d(features*2), nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(features*2, features*4, 4, 2, 1), nn.BatchNorm2d(features*4), nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(features*4, 1, 4, 1, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        return self.model(torch.cat([x, y], dim=1))"
      ],
      "metadata": {
        "id": "qiZwl3tfpJVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn, optim\n",
        "import torchvision.utils as vutils\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "import csv\n",
        "import torch.multiprocessing\n",
        "torch.multiprocessing.set_start_method('spawn', force=True)\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # === Create output directories ===\n",
        "    os.makedirs(\"/content/drive/MyDrive/GANPathology/output_fake\", exist_ok=True)\n",
        "    os.makedirs(\"/content/drive/MyDrive/GANPathology/checkpoints\", exist_ok=True)\n",
        "\n",
        "    # === Data paths ===\n",
        "    input_train = \"/content/drive/MyDrive/GANPathology/dataset/Input/training\"\n",
        "    output_train = \"/content/drive/MyDrive/GANPathology/dataset/output/training\"\n",
        "    input_val = \"/content/drive/MyDrive/GANPathology/dataset/Input/validation\"\n",
        "    output_val = \"/content/drive/MyDrive/GANPathology/dataset/output/validation\"\n",
        "\n",
        "    # === Load datasets ===\n",
        "    train_dataset = PairedImageDataset(input_train, output_train, augment=True)\n",
        "    val_dataset = PairedImageDataset(input_val, output_val, augment=False)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=0)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
        "\n",
        "    # === Model, loss, optimizers ===\n",
        "    G = UNetGeneratorOptimized().cuda()\n",
        "    D = PatchDiscriminator().cuda()\n",
        "\n",
        "    criterion_GAN = nn.BCEWithLogitsLoss()\n",
        "    criterion_L1 = nn.L1Loss()\n",
        "\n",
        "    optimizer_G = optim.Adam(G.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
        "    optimizer_D = optim.Adam(D.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
        "\n",
        "    # === Loss tracking ===\n",
        "    #loss_log_path = \"/rodata/dlmpfl/m300305/loss_log.csv\"\n",
        "    #with open(loss_log_path, mode='w', newline='') as f:\n",
        "        #writer = csv.writer(f)\n",
        "        #writer.writerow([\"Epoch\", \"Train_G_L1\", \"Train_G_GAN\", \"Train_D\", \"Val_L1\"])\n",
        "\n",
        "    num_epochs = 500\n",
        "    best_val_loss = float(\"inf\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        G.train()\n",
        "        D.train()\n",
        "\n",
        "        total_G_L1 = 0.0\n",
        "        total_G_GAN = 0.0\n",
        "        total_D = 0.0\n",
        "\n",
        "        for i, (x, y) in enumerate(train_loader):\n",
        "            x, y = x.cuda(), y.cuda()\n",
        "            fake_y = G(x)\n",
        "\n",
        "            # Train Discriminator\n",
        "            D_real = D(x, y)\n",
        "            D_fake = D(x, fake_y.detach())\n",
        "            loss_D = 0.5 * (\n",
        "                criterion_GAN(D_real, torch.ones_like(D_real)) +\n",
        "                criterion_GAN(D_fake, torch.zeros_like(D_fake))\n",
        "            )\n",
        "            optimizer_D.zero_grad()\n",
        "            loss_D.backward()\n",
        "            optimizer_D.step()\n",
        "\n",
        "            # Train Generator\n",
        "            D_fake = D(x, fake_y)\n",
        "            loss_G_GAN = criterion_GAN(D_fake, torch.ones_like(D_fake))\n",
        "            loss_G_L1 = criterion_L1(fake_y, y)\n",
        "            loss_G = loss_G_GAN + 100 * loss_G_L1\n",
        "\n",
        "            optimizer_G.zero_grad()\n",
        "            loss_G.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "            total_G_GAN += loss_G_GAN.item()\n",
        "            total_G_L1 += loss_G_L1.item()\n",
        "            total_D += loss_D.item()\n",
        "\n",
        "            if i % 10 == 0:\n",
        "                print(f\"[Train] Epoch [{epoch}/{num_epochs}] Step [{i}/{len(train_loader)}] \"\n",
        "                    f\"Loss D: {loss_D.item():.4f}, Loss G: {loss_G.item():.4f}\")\n",
        "\n",
        "        # Validation\n",
        "        G.eval()\n",
        "        total_val_L1 = 0.0\n",
        "        with torch.no_grad():\n",
        "            for j, (x_val, y_val) in enumerate(val_loader):\n",
        "                x_val, y_val = x_val.cuda(), y_val.cuda()\n",
        "                fake_val = G(x_val)\n",
        "                val_L1 = criterion_L1(fake_val, y_val).item()\n",
        "                total_val_L1 += val_L1\n",
        "\n",
        "                if j == 0:\n",
        "                    fake_img = (fake_val[0].cpu() + 1) / 2\n",
        "                    input_img = (x_val[0].cpu() + 1) / 2\n",
        "                    target_img = (y_val[0].cpu() + 1) / 2\n",
        "\n",
        "                    comparison = torch.stack([input_img, fake_img, target_img])\n",
        "                    grid_img = vutils.make_grid(comparison, nrow=3)\n",
        "\n",
        "                    comparison_image = to_pil_image(grid_img)\n",
        "                    plt.figure(figsize=(12, 4))\n",
        "                    plt.imshow(comparison_image)\n",
        "                    plt.title(f\"Epoch {epoch}: Input | Generated | Target\")\n",
        "                    plt.axis('off')\n",
        "                    plt.show()\n",
        "\n",
        "        avg_val_L1 = total_val_L1 / len(val_loader)\n",
        "        avg_G_L1 = total_G_L1 / len(train_loader)\n",
        "        avg_G_GAN = total_G_GAN / len(train_loader)\n",
        "        avg_D = total_D / len(train_loader)\n",
        "\n",
        "        print(f\"[Validation] Epoch [{epoch}/{num_epochs}] Avg L1 Loss: {avg_val_L1:.4f}\")\n",
        "\n",
        "        # Log to CSV\n",
        "        #with open(loss_log_path, mode='a', newline='') as f:\n",
        "            #writer = csv.writer(f)\n",
        "            #writer.writerow([epoch, avg_G_L1, avg_G_GAN, avg_D, avg_val_L1])\n",
        "\n",
        "        # Save per-epoch models\n",
        "        torch.save(G.state_dict(), f\"/content/drive/MyDrive/GANPathology/checkpoints/generator_epoch_{epoch}.pth\")\n",
        "        torch.save(D.state_dict(), f\"/content/drive/MyDrive/GANPathology/checkpoints/discriminator_epoch_{epoch}.pth\")\n",
        "\n",
        "        # Save best models\n",
        "        if avg_val_L1 < best_val_loss:\n",
        "            best_val_loss = avg_val_L1\n",
        "            torch.save(G.state_dict(), f\"/content/drive/MyDrive/GANPathology/checkpoints/best_generator_epoch_{epoch}.pth\")\n",
        "            torch.save(D.state_dict(), f\"/content/drive/MyDrive/GANPathology/checkpoints/best_discriminator_epoch_{epoch}.pth\")\n",
        "            print(f\"✅ Saved best models at epoch {epoch} with val L1 loss: {avg_val_L1:.4f}\")\n",
        "\n",
        "    print(\"✅ Training complete.\")"
      ],
      "metadata": {
        "id": "sVHPWv-KjTj-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}